# üìã PLAN DE DESARROLLO - Sprint 3 ML Microservices

## üéØ Informaci√≥n del Proyecto

**Proyecto:** Sistema de Clasificaci√≥n de Im√°genes con Microservicios  
**Sprint:** 3  
**Tecnolog√≠as:** FastAPI, TensorFlow, Streamlit, Redis, PostgreSQL, Docker  
**Objetivo:** Implementar sistema completo de ML en producci√≥n con arquitectura de microservicios

---

## üìä Estado del Proyecto

**Versiones de Librer√≠as:**
- Mantenemos versiones actuales (2022) por estabilidad
- Solo actualizamos UI a versiones modernas (compatibilidad garantizada)

**Estimaci√≥n Total:** 22-33 horas  
**Fecha Inicio:** 2026-01-13  

---

## üóÇÔ∏è √âPICAS Y TAREAS DETALLADAS

### **√âPICA 0: Setup Inicial del Ambiente** üîß
**ID:** `EPIC-0`  
**Prioridad:** CR√çTICA  
**Estimaci√≥n:** 30 minutos  
**Prerequisito:** Ninguno  
**Branch:** `feature/epic-0-setup`

#### Tareas:

**[EPIC-0-T1] Crear red Docker compartida**
- **ID Tarea:** `EPIC-0-T1`
- **Archivo(s):** N/A (comando Docker)
- **Descripci√≥n:** Crear la red `shared_network` para comunicaci√≥n entre contenedores
- **Implementaci√≥n:**
  ```bash
  docker network create shared_network
  docker network ls | grep shared_network
  ```
- **Validaci√≥n:** La red aparece listada sin errores
- **Commit:** `[EPIC-0-T1] Crear red Docker shared_network`

---

**[EPIC-0-T2] Configurar variables de entorno**
- **ID Tarea:** `EPIC-0-T2`
- **Archivo(s):** `.env`, `api/.env`
- **Descripci√≥n:** Copiar archivos `.env.original` a `.env` en ra√≠z y carpeta api
- **Implementaci√≥n:**
  ```bash
  cp .env.original .env
  cd api && cp .env.original .env && cd ..
  ```
- **Variables requeridas:**
  - `POSTGRES_DB`: Nombre de base de datos
  - `POSTGRES_USER`: Usuario PostgreSQL
  - `POSTGRES_PASSWORD`: Password PostgreSQL
  - `DATABASE_HOST`: Host de base de datos (db)
  - `SECRET_KEY`: Clave secreta JWT
  - `REDIS_IP`: IP de Redis (redis)
- **Validaci√≥n:** Archivos `.env` existen y tienen valores v√°lidos
- **Commit:** `[EPIC-0-T2] Configurar variables de entorno para todos los servicios`

---

**[EPIC-0-T3] Actualizar requirements de UI**
- **ID Tarea:** `EPIC-0-T3`
- **Archivo(s):** `ui/requirements.txt`
- **Descripci√≥n:** Actualizar librer√≠as de UI a versiones modernas (son compatibles)
- **Cambios:**
  ```python
  streamlit==1.40.0
  requests==2.32.3
  Pillow==11.0.0
  pytest==8.3.4
  ```
- **Validaci√≥n:** Build de UI exitoso
- **Commit:** `[EPIC-0-T3] Actualizar dependencias de UI a versiones modernas`

---

### **√âPICA 1: Infraestructura Docker** üê≥
**ID:** `EPIC-1`  
**Prioridad:** CR√çTICA  
**Estimaci√≥n:** 45 minutos  
**Prerequisito:** √âPICA 0 completada  
**Branch:** `feature/epic-1-infrastructure`

#### Tareas:

**[EPIC-1-T1] Implementar Dockerfile.populate**
- **ID Tarea:** `EPIC-1-T1`
- **Archivo(s):** `api/Dockerfile.populate`
- **Descripci√≥n:** Crear Dockerfile para poblar la base de datos inicial
- **Implementaci√≥n:**
  ```dockerfile
  FROM python:3.8.13
  
  ENV PYTHONPATH=$PYTHONPATH:/src/
  
  COPY ./requirements.txt /src/requirements.txt
  WORKDIR /src
  RUN pip install --upgrade pip && pip install -r requirements.txt
  
  COPY ./ /src/
  
  CMD ["python", "populate_db.py"]
  ```
- **Validaci√≥n:** Build exitoso sin errores, script se ejecuta correctamente
- **Commit:** `[EPIC-1-T1] Implementar Dockerfile.populate para inicializaci√≥n de BD`

---

**[EPIC-1-T2] Validar configuraci√≥n docker-compose**
- **ID Tarea:** `EPIC-1-T2`
- **Archivo(s):** `docker-compose.yml`, `api/docker-compose.yml`
- **Descripci√≥n:** Verificar configuraci√≥n de servicios y dependencias
- **Verificaciones:**
  - ‚úÖ Servicio `db` (PostgreSQL) ‚Üí Puerto 5432
  - ‚úÖ Servicio `redis` ‚Üí Puerto 6379
  - ‚úÖ Servicio `model` ‚Üí Depende de redis
  - ‚úÖ Servicio `api` ‚Üí Depende de redis, model, db ‚Üí Puerto 8000
  - ‚úÖ Servicio `ui` ‚Üí Depende de api ‚Üí Puerto 9090
  - ‚úÖ Vol√∫menes compartidos correctamente
  - ‚úÖ Red `shared_network` en todos los servicios
- **Validaci√≥n:** `docker-compose config` sin errores
- **Commit:** `[EPIC-1-T2] Validar y documentar configuraci√≥n docker-compose`

---

### **√âPICA 2: Servicio ML (Model)** ü§ñ
**ID:** `EPIC-2`  
**Prioridad:** ALTA  
**Estimaci√≥n:** 3-4 horas  
**Prerequisito:** √âPICA 1 completada  
**Branch:** `feature/epic-2-ml-service`

#### Tareas:

**[EPIC-2-T1] Conectar Redis en ml_service.py**
- **ID Tarea:** `EPIC-2-T1`
- **Archivo(s):** `model/ml_service.py` (l√≠neas 12-15)
- **Descripci√≥n:** Inicializar conexi√≥n a Redis usando settings
- **Implementaci√≥n:**
  ```python
  db = redis.Redis(
      host=settings.REDIS_IP,
      port=settings.REDIS_PORT,
      db=settings.REDIS_DB_ID
  )
  ```
- **Testing:** Verificar conexi√≥n con `db.ping()`
- **Validaci√≥n:** Conexi√≥n establecida sin excepciones
- **Commit:** `[EPIC-2-T1] Conectar servicio ML a Redis`

---

**[EPIC-2-T2] Cargar modelo ResNet50**
- **ID Tarea:** `EPIC-2-T2`
- **Archivo(s):** `model/ml_service.py` (l√≠neas 17-21)
- **Descripci√≥n:** Cargar modelo preentrenado de TensorFlow
- **Implementaci√≥n:**
  ```python
  model = ResNet50(weights='imagenet')
  ```
- **Notas:** Primera ejecuci√≥n descarga ~100MB, puede tomar 1-2 minutos
- **Validaci√≥n:** Modelo cargado, sin errores de TensorFlow
- **Commit:** `[EPIC-2-T2] Cargar modelo ResNet50 preentrenado`

---

**[EPIC-2-T3] Implementar funci√≥n predict()**
- **ID Tarea:** `EPIC-2-T3`
- **Archivo(s):** `model/ml_service.py` (l√≠neas 24-53)
- **Descripci√≥n:** Cargar imagen, preprocesar y obtener predicci√≥n
- **Pasos de implementaci√≥n:**
  1. Construir path: `img_path = os.path.join(settings.UPLOAD_FOLDER, image_name)`
  2. Cargar imagen: `img = image.load_img(img_path, target_size=(224, 224))`
  3. Convertir a array: `x = image.img_to_array(img)`
  4. Expandir dimensiones: `x = np.expand_dims(x, axis=0)`
  5. Preprocesar: `x = preprocess_input(x)`
  6. Predecir: `preds = model.predict(x)`
  7. Decodificar: `decoded = decode_predictions(preds, top=1)[0][0]`
  8. Extraer: `_, class_name, pred_probability = decoded`
  9. Redondear: `pred_probability = round(float(pred_probability), 4)`
  10. Retornar: `return class_name, pred_probability`
- **Validaci√≥n:** Retorna tupla (str, float) correctamente con dog.jpeg
- **Commit:** `[EPIC-2-T3] Implementar funci√≥n predict() con ResNet50`

---

**[EPIC-2-T4] Implementar funci√≥n classify_process()**
- **ID Tarea:** `EPIC-2-T4`
- **Archivo(s):** `model/ml_service.py` (l√≠neas 56-97)
- **Descripci√≥n:** Loop infinito procesando jobs desde Redis
- **Pasos de implementaci√≥n:**
  1. Obtener job: `queue_name, job_data = db.brpop(settings.REDIS_QUEUE)`
  2. Decodificar: `job = json.loads(job_data)`
  3. Extraer datos: `job_id = job["id"]`, `image_name = job["image_name"]`
  4. Predecir: `class_name, score = predict(image_name)`
  5. Crear output: `output = {"prediction": class_name, "score": score}`
  6. Serializar: `output_json = json.dumps(output)`
  7. Guardar: `db.set(job_id, output_json)`
  8. Sleep: `time.sleep(settings.SERVER_SLEEP)`
- **Manejo de errores:** Try-catch para im√°genes inv√°lidas o errores de modelo
- **Validaci√≥n:** Procesa jobs continuamente, resultados en Redis correctos
- **Commit:** `[EPIC-2-T4] Implementar loop de procesamiento classify_process()`

---

**[EPIC-2-T5] Ejecutar tests del modelo**
- **ID Tarea:** `EPIC-2-T5`
- **Archivo(s):** `model/tests/test_model.py`
- **Descripci√≥n:** Validar que tests unitarios pasan
- **Comando:** `cd model && docker build -t model_test --progress=plain --target test .`
- **Validaci√≥n:** Todos los tests pasan (100%)
- **Commit:** `[EPIC-2-T5] Validar tests unitarios del servicio ML`

---

### **√âPICA 3: API FastAPI** üöÄ
**ID:** `EPIC-3`  
**Prioridad:** ALTA  
**Estimaci√≥n:** 4-5 horas  
**Prerequisito:** √âPICA 2 completada  
**Branch:** `feature/epic-3-api`

#### Tareas:

**[EPIC-3-T1] Implementar allowed_file() en utils.py**
- **ID Tarea:** `EPIC-3-T1`
- **Archivo(s):** `api/app/utils.py` (l√≠neas 5-25)
- **Descripci√≥n:** Validar extensiones de archivo permitidas
- **Implementaci√≥n:**
  ```python
  ALLOWED_EXTENSIONS = {'.png', '.jpg', '.jpeg', '.gif'}
  
  def allowed_file(filename):
      """
      Checks if the format for the file received is acceptable.
      Accepts only image files: .png, .jpg, .jpeg, .gif
      
      Parameters
      ----------
      filename : str
          Filename from werkzeug.datastructures.FileStorage file.
      
      Returns
      -------
      bool
          True if the file is an image, False otherwise.
      """
      if not filename or '.' not in filename:
          return False
      
      file_ext = os.path.splitext(filename)[1].lower()
      return file_ext in ALLOWED_EXTENSIONS
  ```
- **Validaci√≥n:** 
  - Retorna True para .png, .jpg, .jpeg, .gif (case insensitive)
  - Retorna False para .txt, .pdf, etc.
- **Commit:** `[EPIC-3-T1] Implementar validaci√≥n de extensiones de archivo`

---

**[EPIC-3-T2] Implementar get_file_hash() en utils.py**
- **ID Tarea:** `EPIC-3-T2`
- **Archivo(s):** `api/app/utils.py` (l√≠neas 28-53)
- **Descripci√≥n:** Generar hash MD5 del contenido del archivo
- **Implementaci√≥n:**
  ```python
  async def get_file_hash(file):
      """
      Returns a new filename based on the file content using MD5 hashing.
      
      Parameters
      ----------
      file : werkzeug.datastructures.FileStorage
          File sent by user.
      
      Returns
      -------
      str
          New filename based in md5 file hash with original extension.
      """
      # Read file content and generate md5 hash
      file_content = await file.read()
      file_hash = hashlib.md5(file_content).hexdigest()
      
      # Return file pointer to the beginning
      await file.seek(0)
      
      # Add original file extension
      file_extension = os.path.splitext(file.filename)[1].lower()
      
      return f"{file_hash}{file_extension}"
  ```
- **Validaci√≥n:** 
  - Retorna hash MD5 + extensi√≥n original
  - File pointer se resetea correctamente
  - Mismo archivo genera mismo hash
- **Commit:** `[EPIC-3-T2] Implementar generaci√≥n de hash MD5 para archivos`

---

**[EPIC-3-T3] Configurar Redis en model/services.py**
- **ID Tarea:** `EPIC-3-T3`
- **Archivo(s):** `api/app/model/services.py` (l√≠nea 9)
- **Descripci√≥n:** Inicializar conexi√≥n Redis para API
- **Implementaci√≥n:**
  ```python
  import redis
  from app import settings
  
  # Connect to Redis
  db = redis.Redis(
      host=settings.REDIS_IP,
      port=settings.REDIS_PORT,
      db=settings.REDIS_DB_ID,
      decode_responses=False
  )
  ```
- **Validaci√≥n:** Conexi√≥n establecida sin errores
- **Commit:** `[EPIC-3-T3] Configurar conexi√≥n Redis en API`

---

**[EPIC-3-T4] Implementar model_predict() en model/services.py**
- **ID Tarea:** `EPIC-3-T4`
- **Archivo(s):** `api/app/model/services.py` (l√≠neas 15-58)
- **Descripci√≥n:** Enviar job a Redis y esperar resultado
- **Pasos de implementaci√≥n:**
  ```python
  import json
  import time
  import uuid
  
  async def model_predict(image_name):
      """
      Sends image to ML service via Redis and waits for prediction result.
      
      Parameters
      ----------
      image_name : str
          Filename of the image to predict.
      
      Returns
      -------
      prediction : str
          Predicted class name.
      score : float
          Confidence score of prediction.
      """
      # Generate unique job ID
      job_id = str(uuid.uuid4())
      
      # Create job dictionary
      job_data = {
          "id": job_id,
          "image_name": image_name
      }
      
      # Serialize to JSON
      job_json = json.dumps(job_data)
      
      # Push to Redis queue
      db.lpush(settings.REDIS_QUEUE, job_json)
      
      # Poll for result with timeout
      timeout = 60  # seconds
      start_time = time.time()
      
      while True:
          # Check if result is available
          result = db.get(job_id)
          
          if result:
              # Deserialize result
              result_data = json.loads(result)
              prediction = result_data["prediction"]
              score = result_data["score"]
              
              # Clean up
              db.delete(job_id)
              
              return prediction, score
          
          # Check timeout
          if time.time() - start_time > timeout:
              raise TimeoutError(f"Model prediction timeout for job {job_id}")
          
          # Wait before next check
          time.sleep(settings.API_SLEEP)
  ```
- **Validaci√≥n:** Retorna tupla (prediction: str, score: float)
- **Commit:** `[EPIC-3-T4] Implementar comunicaci√≥n API-Model v√≠a Redis`

---

**[EPIC-3-T5] Implementar endpoint predict() en model/router.py**
- **ID Tarea:** `EPIC-3-T5`
- **Archivo(s):** `api/app/model/router.py` (l√≠neas 16-33)
- **Descripci√≥n:** Endpoint completo para clasificaci√≥n de im√°genes
- **Pasos de implementaci√≥n:**
  ```python
  @router.post("/predict")
  async def predict(file: UploadFile, current_user=Depends(get_current_user)):
      rpse = {"success": False, "prediction": None, "score": None, "image_file_name": None}
      
      try:
          # 1. Check if file was sent and is valid
          if not file or not file.filename:
              raise HTTPException(
                  status_code=status.HTTP_400_BAD_REQUEST,
                  detail="No file provided"
              )
          
          # 2. Check if file is an image
          if not utils.allowed_file(file.filename):
              raise HTTPException(
                  status_code=status.HTTP_400_BAD_REQUEST,
                  detail="File type not allowed. Only .png, .jpg, .jpeg, .gif"
              )
          
          # 3. Generate hash and save file
          hashed_filename = await utils.get_file_hash(file)
          file_path = os.path.join(config.UPLOAD_FOLDER, hashed_filename)
          
          # Only save if file doesn't exist (avoid duplicates)
          if not os.path.exists(file_path):
              with open(file_path, "wb") as f:
                  file_content = await file.read()
                  f.write(file_content)
          
          # 4. Send to model service
          prediction, score = await model_predict(hashed_filename)
          
          # 5. Build response
          rpse["success"] = True
          rpse["prediction"] = prediction
          rpse["score"] = float(score)
          rpse["image_file_name"] = hashed_filename
          
      except HTTPException:
          raise
      except Exception as e:
          raise HTTPException(
              status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
              detail=f"Error processing image: {str(e)}"
          )
      
      return PredictResponse(**rpse)
  ```
- **Validaci√≥n:** 
  - Retorna PredictResponse v√°lido
  - Archivos duplicados no se reescriben
  - Errores retornan c√≥digos HTTP apropiados
- **Commit:** `[EPIC-3-T5] Implementar endpoint POST /model/predict`

---

**[EPIC-3-T6] Implementar create_user_registration() en user/router.py**
- **ID Tarea:** `EPIC-3-T6`
- **Archivo(s):** `api/app/user/router.py` (l√≠neas 13-26)
- **Descripci√≥n:** Endpoint para registro de nuevos usuarios
- **Implementaci√≥n:**
  ```python
  @router.post("/", status_code=status.HTTP_201_CREATED)
  async def create_user_registration(
      request: schema.User, database: Session = Depends(db.get_db)
  ):
      # 1. Verify email doesn't exist
      user = await validator.verify_email_exist(request.email, database)
      
      # 2. If email exists, raise 400 error
      if user:
          raise HTTPException(
              status_code=status.HTTP_400_BAD_REQUEST,
              detail="Email already registered"
          )
      
      # 3. Create new user
      new_user = await services.new_user_register(request, database)
      
      # 4. Return new user object
      return new_user
  ```
- **Validaci√≥n:** 
  - Registra usuario nuevo exitosamente
  - Retorna 400 si email ya existe
  - Password se hashea autom√°ticamente
- **Commit:** `[EPIC-3-T6] Implementar endpoint POST /user/ para registro`

---

**[EPIC-3-T7] Ejecutar tests de API**
- **ID Tarea:** `EPIC-3-T7`
- **Archivo(s):** `api/tests/*.py`
- **Descripci√≥n:** Validar que todos los tests unitarios pasan
- **Comando:** `cd api && docker build -t fastapi_test --progress=plain --target test .`
- **Tests incluidos:**
  - `test_router_model.py`
  - `test_router_user.py`
  - `test_router_feedback.py`
  - `test_utils.py`
- **Validaci√≥n:** Todos los tests pasan (100%)
- **Commit:** `[EPIC-3-T7] Validar tests unitarios de API`

---

### **√âPICA 4: Interfaz de Usuario (UI)** üé®
**ID:** `EPIC-4`  
**Prioridad:** MEDIA  
**Estimaci√≥n:** 2-3 horas  
**Prerequisito:** √âPICA 3 completada  
**Branch:** `feature/epic-4-ui`

#### Tareas:

**[EPIC-4-T1] Implementar funci√≥n login()**
- **ID Tarea:** `EPIC-4-T1`
- **Archivo(s):** `ui/app/image_classifier_app.py` (l√≠neas 9-34)
- **Descripci√≥n:** Autenticar usuario y obtener JWT token
- **Implementaci√≥n:**
  ```python
  def login(username: str, password: str) -> Optional[str]:
      """
      Calls the login endpoint of the API to authenticate the user.
      
      Args:
          username (str): email of the user
          password (str): password of the user
      
      Returns:
          Optional[str]: token if login is successful, None otherwise
      """
      try:
          # 1. Construct API endpoint URL
          url = f"{API_BASE_URL}/login"
          
          # 2. Set up headers
          headers = {
              "accept": "application/json",
              "Content-Type": "application/x-www-form-urlencoded",
          }
          
          # 3. Prepare data payload
          data = {
              "grant_type": "",
              "username": username,
              "password": password,
              "scope": "",
              "client_id": "",
              "client_secret": "",
          }
          
          # 4. Send API request
          response = requests.post(url, headers=headers, data=data)
          
          # 5. Check response status
          if response.status_code == 200:
              # 6. Extract token from JSON
              return response.json()["access_token"]
          
      except Exception as e:
          st.error(f"Login error: {str(e)}")
      
      # 7. Return None if failed
      return None
  ```
- **Validaci√≥n:** Retorna token v√°lido con credenciales correctas
- **Commit:** `[EPIC-4-T1] Implementar funci√≥n login() en UI`

---

**[EPIC-4-T2] Implementar funci√≥n predict()**
- **ID Tarea:** `EPIC-4-T2`
- **Archivo(s):** `ui/app/image_classifier_app.py` (l√≠neas 37-57)
- **Descripci√≥n:** Enviar imagen a API para clasificaci√≥n
- **Implementaci√≥n:**
  ```python
  def predict(token: str, uploaded_file: Image) -> requests.Response:
      """
      Calls the predict endpoint of the API to classify the uploaded image.
      
      Args:
          token (str): token to authenticate the user
          uploaded_file (Image): image to classify
      
      Returns:
          requests.Response: response from the API
      """
      # 1. Construct API endpoint URL
      url = f"{API_BASE_URL}/model/predict"
      
      # 2. Add token to headers
      headers = {"Authorization": f"Bearer {token}"}
      
      # 3. Create file dictionary with file data
      files = {
          "file": (uploaded_file.name, uploaded_file.getvalue(), uploaded_file.type)
      }
      
      # 4. Make POST request
      response = requests.post(url, headers=headers, files=files)
      
      # 5. Return response
      return response
  ```
- **Validaci√≥n:** Retorna response con status 200 y JSON v√°lido
- **Commit:** `[EPIC-4-T2] Implementar funci√≥n predict() en UI`

---

**[EPIC-4-T3] Implementar funci√≥n send_feedback()**
- **ID Tarea:** `EPIC-4-T3`
- **Archivo(s):** `ui/app/image_classifier_app.py` (l√≠neas 60-85)
- **Descripci√≥n:** Enviar feedback sobre predicci√≥n a API
- **Implementaci√≥n:**
  ```python
  def send_feedback(
      token: str, feedback: str, score: float, prediction: str, image_file_name: str
  ) -> requests.Response:
      """
      Calls the feedback endpoint of the API to send feedback.
      
      Args:
          token (str): token to authenticate the user
          feedback (str): string with feedback
          score (float): confidence score of the prediction
          prediction (str): predicted class
          image_file_name (str): name of the image file
      
      Returns:
          requests.Response: response from the API
      """
      # 1. Construct API endpoint URL
      url = f"{API_BASE_URL}/feedback/"
      
      # 2. Add token to headers
      headers = {
          "Authorization": f"Bearer {token}",
          "Content-Type": "application/json"
      }
      
      # 3. Create feedback data dictionary
      data = {
          "feedback": feedback,
          "score": score,
          "predicted_class": prediction,
          "image_file_name": image_file_name
      }
      
      # 4. Make POST request
      response = requests.post(url, headers=headers, json=data)
      
      # 5. Return response
      return response
  ```
- **Validaci√≥n:** Retorna 201 cuando feedback se guarda exitosamente
- **Commit:** `[EPIC-4-T3] Implementar funci√≥n send_feedback() en UI`

---

**[EPIC-4-T4] Ejecutar tests de UI**
- **ID Tarea:** `EPIC-4-T4`
- **Archivo(s):** `ui/tests/test_image_classifier_app.py`
- **Descripci√≥n:** Validar tests unitarios de UI
- **Comando:** `cd ui && docker build -t ui_test --progress=plain --target test .`
- **Validaci√≥n:** Tests pasan
- **Commit:** `[EPIC-4-T4] Validar tests unitarios de UI`

---

### **√âPICA 5: Testing de Integraci√≥n** ‚úÖ
**ID:** `EPIC-5`  
**Prioridad:** ALTA  
**Estimaci√≥n:** 1-2 horas  
**Prerequisito:** √âPICAS 2, 3, 4 completadas  
**Branch:** `feature/epic-5-integration`

#### Tareas:

**[EPIC-5-T1] Poblar base de datos**
- **ID Tarea:** `EPIC-5-T1`
- **Archivo(s):** `api/populate_db.py`
- **Descripci√≥n:** Ejecutar script de poblaci√≥n de BD
- **Comandos:**
  ```bash
  cd api
  docker-compose up --build -d
  docker-compose logs app
  ```
- **Validaci√≥n:** Usuario admin@example.com existe en BD
- **Commit:** `[EPIC-5-T1] Poblar base de datos con usuario admin`

---

**[EPIC-5-T2] Levantar sistema completo**
- **ID Tarea:** `EPIC-5-T2`
- **Archivo(s):** `docker-compose.yml`
- **Descripci√≥n:** Iniciar todos los servicios
- **Comandos:**
  ```bash
  docker-compose up --build -d
  docker-compose ps
  ```
- **Validaci√≥n:** Todos los contenedores en estado `Up`
- **Commit:** `[EPIC-5-T2] Validar sistema completo funcional`

---

**[EPIC-5-T3] Ejecutar tests de integraci√≥n E2E**
- **ID Tarea:** `EPIC-5-T3`
- **Archivo(s):** `tests/test_integration.py`
- **Descripci√≥n:** Ejecutar tests end-to-end
- **Comandos:**
  ```bash
  pip install -r tests/requirements.txt
  python tests/test_integration.py
  ```
- **Tests incluidos:**
  - Login exitoso
  - Clasificaci√≥n de imagen
  - Endpoints de feedback
- **Validaci√≥n:** 2 tests pasan (OK)
- **Commit:** `[EPIC-5-T3] Validar tests de integraci√≥n E2E`

---

### **√âPICA 6: Testing de Estr√©s con Locust** üìà
**ID:** `EPIC-6`  
**Prioridad:** MEDIA  
**Estimaci√≥n:** 3-4 horas  
**Prerequisito:** √âPICA 5 completada  
**Branch:** `feature/epic-6-stress-testing`

#### Tareas:

**[EPIC-6-T1] Verificar implementaci√≥n de login en locustfile**
- **ID Tarea:** `EPIC-6-T1`
- **Archivo(s):** `stress_test/locustfile.py` (l√≠neas 9-41)
- **Descripci√≥n:** Ya est√° implementado, verificar funcionalidad
- **Validaci√≥n:** Funci√≥n retorna token v√°lido
- **Commit:** `[EPIC-6-T1] Verificar funci√≥n login en Locust`

---

**[EPIC-6-T2] Implementar test para endpoint index**
- **ID Tarea:** `EPIC-6-T2`
- **Archivo(s):** `stress_test/locustfile.py`
- **Descripci√≥n:** Agregar task para endpoint ra√≠z
- **Implementaci√≥n:**
  ```python
  @task(2)
  def index(self):
      """Test index endpoint with higher frequency"""
      self.client.get("/")
  ```
- **Validaci√≥n:** Task definido y ejecuta correctamente
- **Commit:** `[EPIC-6-T2] Agregar test de endpoint index en Locust`

---

**[EPIC-6-T3] Optimizar test de endpoint predict**
- **ID Tarea:** `EPIC-6-T3`
- **Archivo(s):** `stress_test/locustfile.py` (l√≠neas 51-62)
- **Descripci√≥n:** Mejorar implementaci√≥n existente
- **Mejoras:**
  - Usar `self.client` en lugar de URL hardcoded
  - Cachear token para evitar login repetido
  - Mejor manejo de errores
- **Implementaci√≥n:**
  ```python
  def on_start(self):
      """Called once when user starts - login and cache token"""
      self.token = login("admin@example.com", "admin")
  
  @task(1)
  def predict(self):
      """Test predict endpoint"""
      if not self.token:
          return
      
      files = {"file": ("dog.jpeg", open("dog.jpeg", "rb"), "image/jpeg")}
      headers = {"Authorization": f"Bearer {self.token}"}
      
      self.client.post("/model/predict", headers=headers, files=files)
  ```
- **Validaci√≥n:** Test ejecuta sin errores repetidos de autenticaci√≥n
- **Commit:** `[EPIC-6-T3] Optimizar test de predict en Locust`

---

**[EPIC-6-T4] Ejecutar escenarios de stress testing**
- **ID Tarea:** `EPIC-6-T4`
- **Archivo(s):** N/A (ejecuci√≥n Locust)
- **Descripci√≥n:** Ejecutar 6 escenarios diferentes y recopilar m√©tricas
- **Escenarios:**
  1. 10 usuarios, 1 modelo ‚Üí 5 min
  2. 10 usuarios, 2 modelos ‚Üí 5 min
  3. 25 usuarios, 1 modelo ‚Üí 5 min
  4. 25 usuarios, 2 modelos ‚Üí 5 min
  5. 50 usuarios, 2 modelos ‚Üí 5 min
  6. 50 usuarios, 3 modelos ‚Üí 5 min
- **M√©tricas a recopilar:**
  - RPS (requests por segundo)
  - Response time (median, p95, p99)
  - Failure rate
  - CPU/Memory usage
- **Validaci√≥n:** Datos recopilados en CSV y screenshots
- **Commit:** `[EPIC-6-T4] Recopilar resultados de stress testing`

---

**[EPIC-6-T5] Crear reporte de stress testing**
- **ID Tarea:** `EPIC-6-T5`
- **Archivo(s):** `docs/STRESS_TEST_REPORT.md`
- **Descripci√≥n:** Documento con an√°lisis de performance
- **Contenido requerido:**
  - Descripci√≥n del hardware servidor
  - Tabla comparativa de 6 escenarios
  - Gr√°ficos de Locust (screenshots)
  - An√°lisis de resultados
  - Conclusiones sobre escalabilidad
  - Recomendaciones
- **Validaci√≥n:** Reporte completo en espa√±ol
- **Commit:** `[EPIC-6-T5] Crear reporte de stress testing`

---

### **√âPICA 7: [OPCIONAL] Batch Processing** ‚ö°
**ID:** `EPIC-7`  
**Prioridad:** BAJA (Opcional)  
**Estimaci√≥n:** 4-6 horas  
**Prerequisito:** √âPICA 6 completada  
**Branch:** `feature/epic-7-batch-processing`

#### Tareas:

**[EPIC-7-T1] Dise√±ar arquitectura de batch processing**
- **ID Tarea:** `EPIC-7-T1`
- **Archivo(s):** `docs/BATCH_PROCESSING_DESIGN.md`
- **Descripci√≥n:** Documentar decisiones de dise√±o
- **Decisiones:**
  - Tama√±o de batch: 8 im√°genes (configurable)
  - Timeout: 1 segundo m√°ximo para formar batch
  - Estrategia: H√≠brida (tama√±o O tiempo, lo que ocurra primero)
- **Validaci√≥n:** Documento de dise√±o aprobado
- **Commit:** `[EPIC-7-T1] Documentar arquitectura de batch processing`

---

**[EPIC-7-T2] Agregar configuraci√≥n de batch en settings**
- **ID Tarea:** `EPIC-7-T2`
- **Archivo(s):** `model/settings.py`
- **Descripci√≥n:** Agregar variables de configuraci√≥n
- **Implementaci√≥n:**
  ```python
  # Batch processing settings
  BATCH_SIZE = int(os.getenv("BATCH_SIZE", 8))
  BATCH_TIMEOUT = float(os.getenv("BATCH_TIMEOUT", 1.0))  # seconds
  ENABLE_BATCH = os.getenv("ENABLE_BATCH", "true").lower() == "true"
  ```
- **Validaci√≥n:** Settings cargados correctamente
- **Commit:** `[EPIC-7-T2] Agregar configuraci√≥n para batch processing`

---

**[EPIC-7-T3] Modificar predict() para soportar batch**
- **ID Tarea:** `EPIC-7-T3`
- **Archivo(s):** `model/ml_service.py`
- **Descripci√≥n:** Adaptar funci√≥n para procesar m√∫ltiples im√°genes
- **Implementaci√≥n:**
  ```python
  def predict_batch(image_names):
      """
      Load multiple images and run batch prediction.
      
      Parameters
      ----------
      image_names : list[str]
          List of image filenames.
      
      Returns
      -------
      results : list[tuple(str, float)]
          List of (class_name, probability) for each image.
      """
      images = []
      
      # Load all images
      for image_name in image_names:
          img_path = os.path.join(settings.UPLOAD_FOLDER, image_name)
          img = image.load_img(img_path, target_size=(224, 224))
          x = image.img_to_array(img)
          images.append(x)
      
      # Stack into batch
      batch = np.vstack([np.expand_dims(img, axis=0) for img in images])
      batch = preprocess_input(batch)
      
      # Single prediction call for entire batch
      predictions = model.predict(batch)
      
      # Decode each prediction
      results = []
      for i, preds in enumerate(predictions):
          decoded = decode_predictions(np.expand_dims(preds, axis=0), top=1)[0][0]
          _, class_name, pred_probability = decoded
          results.append((class_name, round(float(pred_probability), 4)))
      
      return results
  ```
- **Validaci√≥n:** Procesa batch correctamente, resultados id√©nticos a versi√≥n individual
- **Commit:** `[EPIC-7-T3] Implementar predict_batch() para m√∫ltiples im√°genes`

---

**[EPIC-7-T4] Modificar classify_process() para acumular jobs**
- **ID Tarea:** `EPIC-7-T4`
- **Archivo(s):** `model/ml_service.py`
- **Descripci√≥n:** Implementar l√≥gica de acumulaci√≥n de jobs
- **Implementaci√≥n:**
  ```python
  def classify_process():
      """
      Loop indefinitely processing jobs in batches.
      """
      jobs_batch = []
      last_process_time = time.time()
      
      while True:
          # Try to get a job with short timeout
          job_data = db.brpop(settings.REDIS_QUEUE, timeout=0.1)
          
          if job_data:
              queue_name, job_json = job_data
              job = json.loads(job_json)
              jobs_batch.append(job)
          
          # Check if we should process the batch
          current_time = time.time()
          should_process = (
              len(jobs_batch) >= settings.BATCH_SIZE or
              (jobs_batch and (current_time - last_process_time) >= settings.BATCH_TIMEOUT)
          )
          
          if should_process and jobs_batch:
              try:
                  # Extract image names and job IDs
                  image_names = [job["image_name"] for job in jobs_batch]
                  job_ids = [job["id"] for job in jobs_batch]
                  
                  # Process batch
                  results = predict_batch(image_names)
                  
                  # Store individual results
                  for job_id, (class_name, score) in zip(job_ids, results):
                      output = {"prediction": class_name, "score": score}
                      db.set(job_id, json.dumps(output))
                  
                  print(f"Processed batch of {len(jobs_batch)} images")
                  
              except Exception as e:
                  print(f"Error processing batch: {e}")
              
              finally:
                  # Reset batch
                  jobs_batch = []
                  last_process_time = time.time()
          
          # Small sleep to avoid busy waiting
          if not jobs_batch:
              time.sleep(settings.SERVER_SLEEP)
  ```
- **Validaci√≥n:** Jobs se procesan en batches correctamente
- **Commit:** `[EPIC-7-T4] Implementar acumulaci√≥n y procesamiento por lotes`

---

**[EPIC-7-T5] Comparar performance con/sin batching**
- **ID Tarea:** `EPIC-7-T5`
- **Archivo(s):** N/A (ejecuci√≥n Locust)
- **Descripci√≥n:** Ejecutar mismos escenarios con batch activado
- **Escenarios:**
  - 50 usuarios, 2 modelos, sin batch (baseline)
  - 50 usuarios, 2 modelos, batch size 4
  - 50 usuarios, 2 modelos, batch size 8
  - 50 usuarios, 2 modelos, batch size 16
- **M√©tricas:** Throughput, latencia p50/p95/p99
- **Validaci√≥n:** Datos comparativos recopilados
- **Commit:** `[EPIC-7-T5] Recopilar m√©tricas de batch processing`

---

**[EPIC-7-T6] Actualizar reporte con resultados de batch**
- **ID Tarea:** `EPIC-7-T6`
- **Archivo(s):** `docs/STRESS_TEST_REPORT.md`
- **Descripci√≥n:** Agregar secci√≥n de batch processing
- **Contenido adicional:**
  - Explicaci√≥n de batch processing
  - Comparativa de performance
  - Trade-offs (throughput vs latencia)
  - Recomendaciones de configuraci√≥n
- **Validaci√≥n:** Reporte actualizado y completo
- **Commit:** `[EPIC-7-T6] Documentar resultados de batch processing`

---

### **√âPICA 8: Calidad y Documentaci√≥n** üìù
**ID:** `EPIC-8`  
**Prioridad:** MEDIA  
**Estimaci√≥n:** 2-3 horas  
**Prerequisito:** √âPICA 5 completada  
**Branch:** `feature/epic-8-quality`

#### Tareas:

**[EPIC-8-T1] Formatear c√≥digo con Black e isort**
- **ID Tarea:** `EPIC-8-T1`
- **Archivo(s):** Todos los archivos `.py`
- **Descripci√≥n:** Aplicar formateo autom√°tico
- **Comandos:**
  ```bash
  make format
  # o manualmente:
  black .
  isort . --recursive --profile black
  ```
- **Validaci√≥n:** 
  - `black --check .` pasa sin cambios
  - `isort --check .` pasa sin cambios
- **Commit:** `[EPIC-8-T1] Formatear c√≥digo con Black e isort`

---

**[EPIC-8-T2] Agregar docstrings faltantes**
- **ID Tarea:** `EPIC-8-T2`
- **Archivo(s):** Funciones implementadas sin docstrings
- **Descripci√≥n:** Documentar todas las funciones p√∫blicas
- **Estilo:** Google docstrings
- **Validaci√≥n:** Todas las funciones p√∫blicas tienen docstrings
- **Commit:** `[EPIC-8-T2] Agregar docstrings a funciones implementadas`

---

**[EPIC-8-T3] Actualizar README principal**
- **ID Tarea:** `EPIC-8-T3`
- **Archivo(s):** `README.md`
- **Descripci√≥n:** Mejorar documentaci√≥n principal
- **Secciones a agregar:**
  - Prerequisitos actualizados
  - Pasos de setup detallados paso a paso
  - Troubleshooting com√∫n
  - URLs de acceso
  - Credenciales por defecto
  - Comandos √∫tiles
- **Validaci√≥n:** README claro y completo
- **Commit:** `[EPIC-8-T3] Actualizar README con instrucciones completas`

---

**[EPIC-8-T4] Crear diagrama de flujo actualizado**
- **ID Tarea:** `EPIC-8-T4`
- **Archivo(s):** `docs/FLOW_DIAGRAM.png`
- **Descripci√≥n:** Diagrama de comunicaci√≥n entre servicios
- **Contenido:**
  - Flujo de autenticaci√≥n
  - Flujo de predicci√≥n (UI ‚Üí API ‚Üí Redis ‚Üí Model ‚Üí Redis ‚Üí API ‚Üí UI)
  - Flujo de feedback
- **Herramientas sugeridas:** draw.io, PlantUML, Mermaid
- **Validaci√≥n:** Diagrama claro y exportado
- **Commit:** `[EPIC-8-T4] Crear diagrama de flujo de comunicaci√≥n`

---

**[EPIC-8-T5] Crear .gitignore completo**
- **ID Tarea:** `EPIC-8-T5`
- **Archivo(s):** `.gitignore`
- **Descripci√≥n:** Asegurar archivos sensibles no se commiteen
- **Contenido:**
  ```gitignore
  # Environment variables
  .env
  .env.local
  .env.*.local
  
  # Python
  __pycache__/
  *.py[cod]
  *$py.class
  *.so
  .Python
  env/
  venv/
  ENV/
  
  # Docker
  db_data/
  
  # Uploads
  uploads/
  *.jpeg
  *.jpg
  *.png
  *.gif
  
  # IDE
  .vscode/
  .idea/
  *.swp
  *.swo
  .DS_Store
  
  # Testing
  .pytest_cache/
  .coverage
  htmlcov/
  
  # Logs
  *.log
  
  # Locust
  *.csv
  locust_*.html
  ```
- **Validaci√≥n:** Git no trackea archivos sensibles
- **Commit:** `[EPIC-8-T5] Agregar .gitignore completo`

---

## üìä Resumen de √âpicas

| √âpica | Tareas | Prioridad | Estimaci√≥n | Branch |
|-------|--------|-----------|------------|--------|
| √âPICA 0: Setup Inicial | 3 | CR√çTICA | 30 min | `feature/epic-0-setup` |
| √âPICA 1: Infraestructura | 2 | CR√çTICA | 45 min | `feature/epic-1-infrastructure` |
| √âPICA 2: Servicio ML | 5 | ALTA | 3-4h | `feature/epic-2-ml-service` |
| √âPICA 3: API FastAPI | 7 | ALTA | 4-5h | `feature/epic-3-api` |
| √âPICA 4: UI Streamlit | 4 | MEDIA | 2-3h | `feature/epic-4-ui` |
| √âPICA 5: Testing Integraci√≥n | 3 | ALTA | 1-2h | `feature/epic-5-integration` |
| √âPICA 6: Stress Testing | 5 | MEDIA | 3-4h | `feature/epic-6-stress-testing` |
| √âPICA 7: Batch Processing | 6 | BAJA (Opcional) | 4-6h | `feature/epic-7-batch-processing` |
| √âPICA 8: Calidad/Docs | 5 | MEDIA | 2-3h | `feature/epic-8-quality` |

**Total de Tareas:** 40  
**Tiempo Total:** 22-33 horas (con batch processing)

---

## üéØ Flujo de Trabajo Git

### Convenci√≥n de Commits:
```
[EPIC-X-TX] Descripci√≥n breve de la tarea

Descripci√≥n m√°s detallada si es necesario.
- Cambios espec√≠ficos
- Archivos modificados

Refs: EPIC-X-TX
```

### Ejemplo:
```
[EPIC-2-T3] Implementar funci√≥n predict() con ResNet50

Implementa la l√≥gica de predicci√≥n de im√°genes:
- Carga y preprocesamiento de im√°genes
- Inferencia con modelo ResNet50
- Decodificaci√≥n de resultados
- Manejo de errores

Archivos modificados:
- model/ml_service.py (l√≠neas 24-53)

Refs: EPIC-2-T3
```

### Workflow:
1. Crear branch para √©pica: `git checkout -b feature/epic-X-nombre`
2. Implementar tarea
3. Commit con formato: `git commit -m "[EPIC-X-TX] Descripci√≥n"`
4. Repetir para cada tarea
5. Merge a `develop` al completar √©pica
6. Merge a `main` al completar hito importante

---

## üìÖ Cronograma Sugerido

### Semana 1:
- **D√≠a 1 (4-5h):** √âPICA 0, 1, 2
- **D√≠a 2 (4-5h):** √âPICA 3
- **D√≠a 3 (3-4h):** √âPICA 4, 5
- **D√≠a 4 (3-4h):** √âPICA 6

### Semana 2 (Opcional):
- **D√≠a 5-6 (4-6h):** √âPICA 7 (Batch Processing)
- **D√≠a 7 (2-3h):** √âPICA 8

---

## ‚úÖ Criterios de Completitud

### Por Tarea:
- [ ] C√≥digo implementado seg√∫n especificaci√≥n
- [ ] Commit realizado con formato correcto
- [ ] Testing manual pasado (ver TESTING_PLAN.md)
- [ ] Sin errores en logs

### Por √âpica:
- [ ] Todas las tareas completadas
- [ ] Tests unitarios pasando (si aplica)
- [ ] Testing manual de √©pica completo
- [ ] Branch mergeado a develop

### Proyecto Completo:
- [ ] Todas las √©picas completadas
- [ ] Tests de integraci√≥n E2E pasando
- [ ] Stress testing ejecutado y reportado
- [ ] Documentaci√≥n actualizada
- [ ] C√≥digo formateado
- [ ] Sistema funcional end-to-end

---

## üìû Soporte

Si encuentras problemas durante el desarrollo:

1. Revisar logs: `docker-compose logs -f [service]`
2. Verificar tests: Ejecutar tests de la √©pica correspondiente
3. Consultar TESTING_PLAN.md para debugging
4. Revisar AGENTS.md para convenciones de c√≥digo

---

**√öltima actualizaci√≥n:** 2026-01-13  
**Versi√≥n:** 1.0
