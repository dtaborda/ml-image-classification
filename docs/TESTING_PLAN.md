# üß™ PLAN DE TESTING - Sprint 3 ML Microservices

## üìã Tabla de Contenidos

1. [Introducci√≥n](#introducci√≥n)
2. [Testing por √âpica](#testing-por-√©pica)
3. [Testing Autom√°tico](#testing-autom√°tico)
4. [Troubleshooting](#troubleshooting)
5. [Checklist Final](#checklist-final)

---

## Introducci√≥n

Este documento contiene la gu√≠a completa de testing manual y autom√°tico para cada √©pica del proyecto. Ejecuta estos tests despu√©s de completar cada √©pica antes de continuar con la siguiente.

### Herramientas Necesarias:
- ‚úÖ Docker Desktop (corriendo)
- ‚úÖ Navegador web (Chrome/Firefox recomendado)
- ‚úÖ Terminal/Consola
- ‚úÖ Python 3.8+ (para tests locales)
- ‚úÖ Cliente HTTP: Postman/Insomnia o curl (opcional)
- ‚úÖ Editor de texto

### üìù Notas Importantes:

**Nombres de Contenedores (Docker Compose v2):**
Docker Compose v2 genera nombres con el formato: `<directorio>-<servicio>-<n√∫mero>`

Ejemplos:
- `redis` ‚Üí `assignment-redis-1`
- `ml_service` ‚Üí `ml_service` (permanece igual)
- `db` ‚Üí `assignment-db-1`

**Encontrar nombres din√°micamente:**
```bash
# Listar contenedores del proyecto
docker ps --filter "name=assignment"

# Encontrar contenedor espec√≠fico
docker ps --filter "name=redis" --format "{{.Names}}"
```

**TTY Issues:**
Si ves el error "the input device is not a TTY", omite las flags `-it`:
```bash
# ‚ùå Puede fallar en algunos entornos
docker exec -it redis redis-cli ping

# ‚úÖ Funciona siempre
docker exec assignment-redis-1 redis-cli ping
```

---

## Testing por √âpica

### üîß √âPICA 0: Setup Inicial del Ambiente

**Cu√°ndo ejecutar:** Despu√©s de completar √âPICA 0  
**Duraci√≥n estimada:** 5 minutos  
**Prerequisitos:** Docker instalado y corriendo

#### Test Manual:

**Test 1: Verificar red Docker**
```bash
docker network ls | grep shared_network
```
‚úÖ **Resultado esperado:** L√≠nea con "shared_network" aparece
```
NETWORK ID     NAME              DRIVER    SCOPE
abc123def456   shared_network    bridge    local
```

**Test 2: Verificar archivos .env**
```bash
# En directorio ra√≠z del proyecto
ls -la .env
ls -la api/.env
```
‚úÖ **Resultado esperado:** Ambos archivos existen
```
-rw-r--r--  1 user  staff  142 Jan 13 10:00 .env
-rw-r--r--  1 user  staff  142 Jan 13 10:00 api/.env
```

**Test 3: Verificar contenido de .env**
```bash
cat .env
```
‚úÖ **Resultado esperado:** Contiene variables requeridas:
- POSTGRES_DB
- POSTGRES_USER
- POSTGRES_PASSWORD
- DATABASE_HOST
- SECRET_KEY

**Test 4: Verificar actualizaci√≥n de ui/requirements.txt**
```bash
cat ui/requirements.txt
```
‚úÖ **Resultado esperado:**
```
streamlit==1.40.0
requests==2.32.3
Pillow==11.0.0
pytest==8.3.4
```

#### Criterios de √âxito:
- [‚úÖ] Red shared_network creada
- [‚úÖ] Archivos .env en su lugar
- [‚úÖ] Variables de entorno configuradas
- [‚úÖ] Requirements de UI actualizados

---

### üê≥ √âPICA 1: Infraestructura Docker

**Cu√°ndo ejecutar:** Despu√©s de completar √âPICA 1  
**Duraci√≥n estimada:** 10 minutos  
**Prerequisitos:** √âPICA 0 completada

#### Test Manual:

**Test 1: Validar Dockerfile.populate**
```bash
cd api
docker build -f Dockerfile.populate -t test_populate .
```
‚úÖ **Resultado esperado:** Build exitoso sin errores
```
Successfully built abc123def456
Successfully tagged test_populate:latest
```

**Test 2: Verificar docker-compose config**
```bash
cd ..  # Volver a ra√≠z
docker-compose config
```
‚úÖ **Resultado esperado:** YAML v√°lido sin errores, muestra configuraci√≥n completa

**Test 3: Verificar servicios definidos**
```bash
docker-compose config --services
```
‚úÖ **Resultado esperado:**
```
api
db
model
redis
ui
```

**Test 4: Validar puertos**
```bash
# Comando corregido: grep solo en la secci√≥n de ports (no volumes)
docker-compose config | grep -A 5 "ports:" | grep -E "(published|target)" | grep -v "volumes" | head -15
```
‚úÖ **Resultado esperado:** (Formato Docker Compose v2)
```
        published: "8000"
        target: 5000
        published: "5432"
        target: 5432
        published: "9090"
        target: 9090
```

**Interpretaci√≥n:**
- API: `8000` (host) ‚Üí `5000` (container) = `8000:5000`
- DB: `5432` (host) ‚Üí `5432` (container) = `5432:5432`
- UI: `9090` (host) ‚Üí `9090` (container) = `9090:9090`

‚ö†Ô∏è **Nota:** Si ves `target: /src/uploads` o paths de archivos, esos son vol√∫menes, no puertos. Ign√≥ralos.

**Nota sobre warnings:**
```
WARN: the attribute `version` is obsolete
```
‚ö†Ô∏è Este warning es normal en Docker Compose v2 y puede ignorarse.

**Test 5: Test build de todos los servicios**
```bash
docker-compose build
```
‚úÖ **Resultado esperado:** Todos los servicios construyen exitosamente

‚è±Ô∏è **Nota importante:** Puede tomar 5-10 minutos la primera vez:
- Descarga TensorFlow 2.13.0 (~500MB en Apple Silicon)
- Descarga base images de Python
- Instala todas las dependencias

‚ö†Ô∏è **Para Apple Silicon (M1/M2/M3):**
Si ves errores relacionados con TensorFlow 2.8.0 o Pillow 11.0.0:
- Esto ya fue corregido en commits recientes
- Ver `docs/COMPATIBILITY_NOTES.md` para detalles
- Las versiones actualizadas son compatibles (TF 2.13.0, Pillow 10.4.0)

#### Criterios de √âxito:
- [ ] Dockerfile.populate construye sin errores
- [ ] docker-compose.yml es v√°lido
- [ ] Todos los servicios se construyen correctamente
- [ ] Puertos configurados correctamente

---

### ü§ñ √âPICA 2: Servicio ML (Model)

**Cu√°ndo ejecutar:** Despu√©s de completar √âPICA 2  
**Duraci√≥n estimada:** 15 minutos  
**Prerequisitos:** √âPICA 1 completada

#### Test Manual:

**Test 1: Levantar servicios necesarios**
```bash
docker-compose up -d redis model
docker-compose ps
```
‚úÖ **Resultado esperado:** Ambos servicios en estado "Up"
```
NAME         STATUS    PORTS
redis        Up        6379/tcp
ml_service   Up
```

**Test 2: Verificar logs del modelo**
```bash
docker-compose logs model
```
‚úÖ **Resultado esperado:**
- "Launching ML service..." aparece
- No hay errores de TensorFlow
- No hay errores de conexi√≥n Redis
- Puede aparecer mensaje de descarga de modelo (primera vez)

**Test 3: Verificar conexi√≥n Redis**
```bash
# Docker Compose v2 genera nombres como: <directorio>-<servicio>-<n√∫mero>
# M√©todo 1: Usar el nombre completo
docker exec assignment-redis-1 redis-cli ping

# M√©todo 2: Encontrar el nombre din√°micamente
docker ps --filter "name=redis" --format "{{.Names}}" | xargs -I {} docker exec {} redis-cli ping
```
‚úÖ **Resultado esperado:**
```
PONG
```

**Nota:** Si el comando con `-it` falla con "the input device is not a TTY", omite esas flags.

**Test 4: Test interactivo de predicci√≥n (Opcional)**
```bash
# Copiar imagen de prueba al volumen
cp api/tests/dog.jpeg uploads/

# Entrar al contenedor del modelo
docker exec -it ml_service python

# En el int√©rprete Python:
>>> from ml_service import predict
>>> result = predict("dog.jpeg")
>>> print(result)
>>> exit()
```
‚úÖ **Resultado esperado:** Tupla con nombre de clase y probabilidad
```python
('golden_retriever', 0.8234)
```

**Test 5: Test de comunicaci√≥n Redis**
```bash
# Opci√≥n A: Comandos directos (sin TTY)
docker exec assignment-redis-1 redis-cli LPUSH service_queue '{"id":"test123","image_name":"dog.jpeg"}'
sleep 3
docker exec assignment-redis-1 redis-cli GET test123

# Opci√≥n B: Modo interactivo (si tu terminal lo soporta)
docker exec -it assignment-redis-1 redis-cli
# Dentro de redis-cli:
127.0.0.1:6379> LPUSH service_queue '{"id":"test123","image_name":"dog.jpeg"}'
127.0.0.1:6379> GET test123
# Esperar 2-3 segundos
127.0.0.1:6379> GET test123
127.0.0.1:6379> exit
```
‚úÖ **Resultado esperado:** Segunda vez retorna JSON con prediction y score
```json
{"prediction":"golden_retriever","score":0.8234}
```

**Test 6: Verificar modelo descarg√≥ correctamente**
```bash
docker-compose logs model | grep -i "model"
```
‚úÖ **Resultado esperado:** Sin errores de carga de modelo

#### Test Autom√°tico:

**Test de unidad del modelo**
```bash
cd model
docker build -t model_test --progress=plain --target test .
```

**‚ö†Ô∏è Si falla con "TLS handshake timeout" (problema de red con Docker Hub):**
```bash
# Workaround: Ejecutar tests en el contenedor corriendo
docker exec ml_service pytest -v /src/tests
```

‚úÖ **Resultado esperado:**
```
============================= test session starts ==============================
tests/test_model.py::test_predict PASSED                                [100%]

============================== 1 passed in 4.86s ===============================
```

**Nota:** El tiempo puede variar (4-18 segundos) dependiendo de si es la primera predicci√≥n.

#### Criterios de √âxito:
- [ ] Contenedores corriendo estables
- [ ] Modelo ResNet50 cargado exitosamente
- [ ] Predicciones funcionan correctamente
- [ ] Redis recibe y procesa jobs
- [ ] Tests unitarios pasan

---

### üöÄ √âPICA 3: API FastAPI

**Cu√°ndo ejecutar:** Despu√©s de completar √âPICA 3  
**Duraci√≥n estimada:** 20 minutos  
**Prerequisitos:** √âPICA 2 completada

#### Test Manual:

**Test 1: Poblar base de datos**
```bash
cd api
docker-compose up --build -d
docker-compose logs app
```
‚úÖ **Resultado esperado:**
- Container ejecuta sin errores
- Logs muestran creaci√≥n de usuario admin

**Test 2: Levantar sistema completo**
```bash
cd ..  # Volver a ra√≠z
docker-compose up -d
docker-compose ps
```
‚úÖ **Resultado esperado:** Todos los servicios "Up"
```
NAME         STATUS    PORTS
ml_api       Up        0.0.0.0:8000->5000/tcp
ml_service   Up
ml_ui        Up        0.0.0.0:9090->9090/tcp
postgres_db  Up        0.0.0.0:5432->5432/tcp
redis        Up        6379/tcp
```

**Test 3: Verificar API responde**
```bash
curl http://localhost:8000/docs
```
‚úÖ **Resultado esperado:** HTML de Swagger UI retornado

**Test 4: Testing en Swagger UI**

1. **Abrir navegador:**
   - URL: http://localhost:8000/docs
   - ‚úÖ Interfaz de FastAPI carga correctamente

2. **Login:**
   - Endpoint: `POST /login`
   - Click "Try it out"
   - Llenar:
     - username: `admin@example.com`
     - password: `admin`
   - Click "Execute"
   - ‚úÖ Response 200 con JSON:
     ```json
     {
       "access_token": "eyJ...",
       "token_type": "bearer"
     }
     ```
   - **COPIAR el access_token**

3. **Autorizar:**
   - Click bot√≥n "Authorize" (üîì) arriba a la derecha
   - Pegar: `Bearer <tu_token_aqui>`
   - Click "Authorize"
   - ‚úÖ Bot√≥n cambia a "Authorized" (üîí)

4. **Crear usuario nuevo:**
   - Endpoint: `POST /user/`
   - Try it out
   - Request body:
     ```json
     {
       "name": "Test User",
       "email": "test@test.com",
       "password": "test123"
     }
     ```
   - Execute
   - ‚úÖ Response 201 con usuario creado
   - ‚úÖ Password NO aparece en respuesta (seguridad)

5. **Intentar crear usuario duplicado:**
   - Mismo endpoint, mismo email
   - ‚úÖ Response 400: "Email already registered"

6. **Test de predicci√≥n:**
   - Endpoint: `POST /model/predict`
   - Try it out
   - Click "Choose File" ‚Üí Seleccionar `api/tests/dog.jpeg`
   - Execute
   - ‚è±Ô∏è Esperar 3-5 segundos
   - ‚úÖ Response 200:
     ```json
     {
       "success": true,
       "prediction": "golden_retriever",
       "score": 0.8234,
       "image_file_name": "a1b2c3d4e5f6.jpeg"
     }
     ```

7. **Verificar archivo guardado:**
   ```bash
   ls -la uploads/
   ```
   - ‚úÖ Archivo con hash MD5 existe

8. **Test de predicci√≥n duplicada:**
   - Mismo archivo, mismo endpoint
   - ‚úÖ Retorna mismo hash (no duplica archivo)

9. **Test con archivo inv√°lido:**
   - Subir archivo .txt
   - ‚úÖ Response 400: "File type not allowed"

10. **Enviar feedback:**
    - Endpoint: `POST /feedback/`
    - Try it out
    - Request body:
      ```json
      {
        "score": 0.8234,
        "predicted_class": "golden_retriever",
        "image_file_name": "a1b2c3d4e5f6.jpeg",
        "feedback": "La predicci√≥n fue incorrecta, es un labrador"
      }
      ```
    - Execute
    - ‚úÖ Response 201

11. **Ver feedback enviado:**
    - Endpoint: `GET /feedback/`
    - Execute
    - ‚úÖ Response 200 con array conteniendo el feedback

**Test 5: Test con curl (alternativo)**
```bash
# Login
TOKEN=$(curl -X POST "http://localhost:8000/login" \
  -H "Content-Type: application/x-www-form-urlencoded" \
  -d "username=admin@example.com&password=admin" | jq -r '.access_token')

# Predicci√≥n
curl -X POST "http://localhost:8000/model/predict" \
  -H "Authorization: Bearer $TOKEN" \
  -F "file=@api/tests/dog.jpeg"
```
‚úÖ **Resultado esperado:** JSON con predicci√≥n

#### Test Autom√°tico:

**Tests unitarios de API**
```bash
cd api
docker build -t fastapi_test --progress=plain --target test .
```
‚úÖ **Resultado esperado:**
```
============================= test session starts ==============================
tests/test_utils.py::test_allowed_file PASSED                           [ 25%]
tests/test_router_user.py::test_create_user_registration_success PASSED [ 50%]
tests/test_router_user.py::test_create_user_registration_fails PASSED   [ 75%]
tests/test_router_model.py::test_predict PASSED                         [100%]

============================== 4 passed in 2.45s ===============================
```

#### Criterios de √âxito:
- [ ] API responde en puerto 8000
- [ ] Swagger UI carga correctamente
- [ ] Login funciona y retorna token
- [ ] Autorizaci√≥n JWT funciona
- [ ] CRUD de usuarios funciona
- [ ] Predicci√≥n retorna resultados correctos
- [ ] Archivos se guardan con hash MD5
- [ ] Validaci√≥n de tipos de archivo funciona
- [ ] Feedback se guarda en BD
- [ ] Tests unitarios pasan

---

### üé® √âPICA 4: UI Streamlit

**Cu√°ndo ejecutar:** Despu√©s de completar √âPICA 4  
**Duraci√≥n estimada:** 15 minutos  
**Prerequisitos:** √âPICA 3 completada, sistema completo corriendo

#### Test Manual:

**Test 1: Verificar UI carga**
1. Abrir navegador
2. Ir a: http://localhost:9090
3. ‚úÖ P√°gina "Image Classifier" carga
4. ‚úÖ Formulario de login visible

**Test 2: Login en UI**
1. Username: `admin@example.com`
2. Password: `admin`
3. Click "Login"
4. ‚úÖ Mensaje: "Login successful!"
5. ‚úÖ Aparece uploader de imagen
6. ‚úÖ Formulario de login desaparece

**Test 3: Login con credenciales incorrectas**
1. Refrescar p√°gina (F5)
2. Username: `wrong@email.com`
3. Password: `wrongpass`
4. Click "Login"
5. ‚úÖ Mensaje: "Login failed. Please check your credentials."
6. ‚úÖ NO aparece uploader

**Test 4: Upload de imagen**
1. Login exitoso
2. Click "Browse files"
3. Seleccionar imagen (dog.jpeg o cualquier .jpg/.png)
4. ‚úÖ Imagen se muestra en pantalla
5. ‚úÖ Preview con tama√±o 300px de ancho

**Test 5: Clasificaci√≥n de imagen**
1. Despu√©s de subir imagen
2. Click bot√≥n "Classify"
3. ‚è±Ô∏è Esperar 3-5 segundos
4. ‚úÖ Aparece:
   - **Prediction:** nombre_clase (ej: "golden_retriever")
   - **Score:** n√∫mero decimal (ej: 0.8234)
5. ‚úÖ Aparece secci√≥n "Feedback"

**Test 6: Clasificar sin subir imagen**
1. Login exitoso
2. Click "Classify" SIN subir imagen
3. ‚úÖ Warning: "Please upload an image before classifying."

**Test 7: Env√≠o de feedback**
1. Despu√©s de clasificar exitosamente
2. En textarea de feedback escribir: "La predicci√≥n es incorrecta"
3. Click "Send Feedback"
4. ‚úÖ Mensaje: "Thanks for your feedback!"

**Test 8: Feedback sin texto**
1. Despu√©s de clasificar
2. Dejar textarea vac√≠o
3. Click "Send Feedback"
4. ‚úÖ Warning: "Please provide feedback before sending."

**Test 9: Verificar feedback en API**
1. Ir a http://localhost:8000/docs
2. Login y autorizar
3. GET /feedback/
4. ‚úÖ Feedback enviado desde UI aparece en la lista

**Test 10: Test con diferentes formatos**
1. Subir imagen .jpg ‚Üí ‚úÖ Funciona
2. Subir imagen .png ‚Üí ‚úÖ Funciona
3. Subir imagen .gif ‚Üí ‚úÖ Funciona
4. Intentar subir .txt ‚Üí ‚úÖ Streamlit rechaza (por configuraci√≥n)

**Test 11: Persistencia de sesi√≥n**
1. Clasificar imagen exitosamente
2. Refrescar p√°gina (F5)
3. ‚úÖ Vuelve a pedir login (sesi√≥n no persiste por dise√±o)

**Test 12: M√∫ltiples clasificaciones**
1. Login
2. Subir imagen 1, clasificar
3. Subir imagen 2 diferente, clasificar
4. ‚úÖ Ambas clasificaciones funcionan
5. ‚úÖ Resultados actualizados correctamente

#### Test Autom√°tico:

**Tests unitarios de UI**
```bash
cd ui
docker build -t ui_test --progress=plain --target test .
```
‚úÖ **Resultado esperado:** Tests pasan

#### Criterios de √âxito:
- [ ] UI carga en puerto 9090
- [ ] Login funciona con credenciales correctas
- [ ] Login falla con credenciales incorrectas
- [ ] Upload de im√°genes funciona
- [ ] Preview de imagen se muestra
- [ ] Clasificaci√≥n retorna resultados
- [ ] Feedback se env√≠a correctamente
- [ ] Validaciones de campos funcionan
- [ ] UI es responsive y usable

---

### ‚úÖ √âPICA 5: Testing de Integraci√≥n

**Cu√°ndo ejecutar:** Despu√©s de completar √âPICA 5  
**Duraci√≥n estimada:** 10 minutos  
**Prerequisitos:** √âPICAS 2, 3, 4 completadas

#### Test Autom√°tico E2E:

**Setup:**
```bash
# Instalar dependencias
pip install -r tests/requirements.txt
```

**Ejecuci√≥n:**
```bash
# Asegurar que sistema est√° corriendo
docker-compose ps

# Ejecutar tests
python tests/test_integration.py
```

‚úÖ **Resultado esperado:**
```
..
----------------------------------------------------------------------
Ran 2 tests in 5.299s

OK
```

**Si hay fallos, verificar:**
```bash
# ¬øAPI est√° corriendo?
curl http://localhost:8000/

# ¬øUsuario admin existe?
docker-compose exec api python -c "from app.db import get_db; from app.user.models import User; db = next(get_db()); print(db.query(User).filter(User.email=='admin@example.com').first())"

# Ver logs
docker-compose logs api
docker-compose logs model
```

#### Test Manual Complementario:

**Test de flujo completo con curl:**
```bash
# 1. Login
curl -X POST "http://localhost:8000/login" \
  -H "Content-Type: application/x-www-form-urlencoded" \
  -d "username=admin@example.com&password=admin"

# 2. Copiar token y usar en predicci√≥n
TOKEN="<pegar_token_aqui>"

curl -X POST "http://localhost:8000/model/predict" \
  -H "Authorization: Bearer $TOKEN" \
  -F "file=@tests/dog.jpeg"

# 3. Enviar feedback
curl -X POST "http://localhost:8000/feedback/" \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "feedback": "Test feedback",
    "score": 0.85,
    "predicted_class": "golden_retriever",
    "image_file_name": "test.jpeg"
  }'
```

‚úÖ **Resultado esperado:** Todos los requests retornan c√≥digos 200/201

#### Criterios de √âxito:
- [ ] Tests autom√°ticos E2E pasan (2/2)
- [ ] Flujo completo funciona via curl
- [ ] Todos los servicios comunic√°ndose correctamente
- [ ] No hay errores en logs

---

### üìà √âPICA 6: Testing de Estr√©s con Locust

**Cu√°ndo ejecutar:** Despu√©s de completar √âPICA 6  
**Duraci√≥n estimada:** 60 minutos (6 escenarios)  
**Prerequisitos:** √âPICA 5 completada, sistema corriendo

#### Setup:

**Instalaci√≥n:**
```bash
pip install locust
locust --version
```

**Preparaci√≥n:**
```bash
cd stress_test
ls dog.jpeg  # Verificar imagen existe
```

#### Test Manual:

**Test 1: Lanzar Locust**
```bash
locust -f locustfile.py --host=http://localhost:8000
```
‚úÖ **Resultado esperado:**
```
[2026-01-13 10:00:00,000] INFO/locust.main: Starting web interface at http://0.0.0.0:8089
```

**Test 2: Configurar prueba inicial**
1. Abrir navegador: http://localhost:8089
2. Configurar:
   - Number of users: **10**
   - Ramp up: **1** user/second
   - Host: `http://localhost:8000`
3. Click "Start swarming"
4. ‚úÖ Simulaci√≥n inicia sin errores

**Test 3: Monitorear m√©tricas**
En interfaz de Locust observar:
- **Statistics tab:**
  - Requests/s (RPS)
  - Response times (50%, 95%, 99%)
  - Failures (debe ser 0%)
- **Charts tab:**
  - Gr√°fico de RPS en tiempo real
  - Gr√°fico de response times
- **Failures tab:**
  - ‚úÖ Debe estar vac√≠o

**Test 4: Escenario 1 - Baseline (10 usuarios, 1 modelo)**
```bash
# Ya corriendo desde Test 2
# Dejar correr 5 minutos
```
üìä **M√©tricas esperadas:**
- RPS: 2-5 req/s
- Response time median: 1000-2000ms
- Response time 95%: 2000-3000ms
- Failure rate: 0%

**Exportar datos:**
1. Click "Download Data" tab
2. Descargar:
   - statistics.csv
   - statistics_history.csv
3. Screenshots de gr√°ficos

**Test 5: Escenario 2 - Escalado (10 usuarios, 2 modelos)**
```bash
# En otra terminal
docker-compose up --scale model=2 -d

# Verificar
docker-compose ps | grep model
# Debe mostrar 2 instancias
```

En Locust UI:
1. Click "Stop"
2. Click "New test"
3. Misma configuraci√≥n (10 usuarios, 1/s)
4. Correr 5 minutos

üìä **M√©tricas esperadas:**
- RPS: 4-8 req/s (mejora ~2x)
- Response time median: 800-1500ms (mejora)
- Failure rate: 0%

**Test 6: Escenario 3-6 - Carga progresiva**

| Escenario | Usuarios | Modelos | Duraci√≥n |
|-----------|----------|---------|----------|
| 3 | 25 | 1 | 5 min |
| 4 | 25 | 2 | 5 min |
| 5 | 50 | 2 | 5 min |
| 6 | 50 | 3 | 5 min |

Para cada escenario:
1. Escalar modelos: `docker-compose up --scale model=N -d`
2. Stop + New test en Locust
3. Configurar usuarios
4. Correr 5 minutos
5. Exportar datos y screenshots

**Test 7: Monitoreo de recursos**
```bash
# En otra terminal durante tests
docker stats

# Observar:
# - CPU% de cada contenedor
# - Memory usage
```

üìä **Anotar m√©tricas de recursos:**
- CPU usage de model container(s)
- CPU usage de api container
- Memory usage

**Test 8: Test de estabilidad (opcional)**
```bash
# Escenario largo: 50 usuarios, 3 modelos, 30 minutos
```
‚úÖ **Objetivo:** Verificar que no hay memory leaks o degradaci√≥n

#### Formato de Reporte:

Crear archivo `docs/STRESS_TEST_REPORT.md` con:

```markdown
# Reporte de Stress Testing

## Hardware Utilizado
- CPU: [especificar]
- RAM: [especificar]
- OS: [especificar]
- Docker: [versi√≥n]

## Resultados

### Tabla Comparativa

| Escenario | Usuarios | Modelos | RPS | RT p50 (ms) | RT p95 (ms) | Failures |
|-----------|----------|---------|-----|-------------|-------------|----------|
| 1 | 10 | 1 | X | X | X | X% |
| 2 | 10 | 2 | X | X | X | X% |
| ... | ... | ... | ... | ... | ... | ... |

### Gr√°ficos
[Screenshots de Locust]

## An√°lisis
[Interpretaci√≥n de resultados]

## Conclusiones
[Recomendaciones]
```

#### Criterios de √âxito:
- [ ] Locust ejecuta sin crashes
- [ ] 6 escenarios completados
- [ ] Datos exportados para cada escenario
- [ ] Screenshots capturados
- [ ] Se observa mejora con m√°s instancias
- [ ] Failure rate < 5%
- [ ] Reporte creado

---

### ‚ö° √âPICA 7: Batch Processing (Opcional)

**Cu√°ndo ejecutar:** Despu√©s de completar √âPICA 7  
**Duraci√≥n estimada:** 30 minutos  
**Prerequisitos:** √âPICA 6 completada, batch implementado

#### Test Manual:

**Test 1: Verificar configuraci√≥n batch**
```bash
cat model/settings.py | grep -A 3 "BATCH"
```
‚úÖ **Resultado esperado:**
```python
BATCH_SIZE = 8
BATCH_TIMEOUT = 1.0
ENABLE_BATCH = true
```

**Test 2: Activar batch processing**
```bash
# Si usa variables de entorno
export ENABLE_BATCH=true
export BATCH_SIZE=8

# Reiniciar servicio
docker-compose restart model
```

**Test 3: Verificar logs de batch**
```bash
docker-compose logs -f model | grep -i batch
```
‚úÖ **Resultado esperado:**
```
Processing batch of 4 images in 0.8s
Processing batch of 8 images in 1.2s
```

**Test 4: Test funcional - predicciones siguen correctas**
1. Ir a UI: http://localhost:9090
2. Login
3. Clasificar varias im√°genes
4. ‚úÖ Resultados siguen siendo correctos
5. ‚úÖ No hay diferencia en calidad de predicciones

**Test 5: Comparativa con Locust**

**Sin batch:**
```bash
# Desactivar batch
export ENABLE_BATCH=false
docker-compose restart model

# Locust: 50 usuarios, 2 modelos, 5 min
locust -f locustfile.py --host=http://localhost:8000
```
üìä Anotar m√©tricas baseline

**Con batch (tama√±o 4):**
```bash
export ENABLE_BATCH=true
export BATCH_SIZE=4
docker-compose restart model

# Locust: mismo escenario
```
üìä Anotar m√©tricas

**Con batch (tama√±o 8):**
```bash
export BATCH_SIZE=8
docker-compose restart model
```
üìä Anotar m√©tricas

**Con batch (tama√±o 16):**
```bash
export BATCH_SIZE=16
docker-compose restart model
```
üìä Anotar m√©tricas

**Test 6: An√°lisis de trade-offs**

Comparar:
- **Throughput:** Im√°genes procesadas/segundo
- **Latencia p50:** Tiempo de respuesta mediano
- **Latencia p95/p99:** Peor caso

üìä **Esperado:**
- Throughput: ‚¨ÜÔ∏è +30-50% con batch
- Latencia p50: ‚û°Ô∏è Similar
- Latencia p95/p99: ‚¨ÜÔ∏è Aumenta ligeramente (trade-off)

#### Actualizar Reporte:

Agregar a `docs/STRESS_TEST_REPORT.md`:

```markdown
## Batch Processing

### Configuraci√≥n
- Tama√±o de batch: 8
- Timeout: 1.0s
- Estrategia: H√≠brida

### Resultados Comparativos

| Configuraci√≥n | Throughput (img/s) | Latencia p50 (ms) | Latencia p95 (ms) |
|---------------|-------------------|-------------------|-------------------|
| Sin batch | X | X | X |
| Batch size 4 | X | X | X |
| Batch size 8 | X | X | X |
| Batch size 16 | X | X | X |

### An√°lisis
[Explicar trade-offs]

### Recomendaciones
Configuraci√≥n √≥ptima: batch size = X porque...
```

#### Criterios de √âxito:
- [ ] Batch processing funciona correctamente
- [ ] Logs muestran procesamiento por lotes
- [ ] Calidad de predicciones se mantiene
- [ ] Throughput mejora significativamente
- [ ] Trade-offs documentados
- [ ] Reporte actualizado

---

### üìù √âPICA 8: Calidad y Documentaci√≥n

**Cu√°ndo ejecutar:** Despu√©s de completar √âPICA 8  
**Duraci√≥n estimada:** 10 minutos  
**Prerequisitos:** √âPICA 5 completada

#### Test Manual:

**Test 1: Verificar formateo de c√≥digo**
```bash
# Ejecutar formateo
make format

# Verificar que no hay cambios pendientes
black --check .
isort --check . --profile black
```
‚úÖ **Resultado esperado:**
```
All done! ‚ú® üç∞ ‚ú®
XX files would be left unchanged.
```

**Test 2: Validar docstrings**
```bash
# Verificar funciones implementadas tienen docstrings
grep -r "def " api/app/utils.py
grep -A 5 "def allowed_file" api/app/utils.py
```
‚úÖ **Resultado esperado:** Cada funci√≥n tiene docstring estilo Google

**Test 3: Verificar README actualizado**
```bash
cat README.md
```
‚úÖ **Debe contener:**
- [ ] Secci√≥n de prerequisitos
- [ ] Pasos de setup claros
- [ ] URLs de acceso
- [ ] Credenciales por defecto
- [ ] Secci√≥n de troubleshooting

**Test 4: Verificar .gitignore**
```bash
cat .gitignore
```
‚úÖ **Debe incluir:**
- .env
- __pycache__/
- uploads/
- db_data/
- *.pyc
- .pytest_cache/

**Test 5: Verificar que archivos sensibles no est√°n trackeados**
```bash
git status
```
‚úÖ **NO debe aparecer:**
- .env
- Archivos en uploads/
- __pycache__/
- db_data/

#### Criterios de √âxito:
- [ ] C√≥digo formateado con Black
- [ ] Imports ordenados con isort
- [ ] Docstrings presentes
- [ ] README completo y claro
- [ ] .gitignore protege archivos sensibles
- [ ] Diagrama de flujo creado (si aplica)

---

## Testing Autom√°tico

### Resumen de Comandos de Tests

**Tests Unitarios por Servicio:**
```bash
# API
cd api && docker build -t fastapi_test --target test .

# Model
cd model && docker build -t model_test --target test .

# UI
cd ui && docker build -t ui_test --target test .
```

**Tests de Integraci√≥n:**
```bash
pip install -r tests/requirements.txt
python tests/test_integration.py
```

**Todos los tests en secuencia:**
```bash
# Script automatizado
./run_all_tests.sh  # (crear este script)
```

### Script run_all_tests.sh

```bash
#!/bin/bash

echo "üß™ Ejecutando todos los tests..."

echo "\nüì¶ Tests API..."
cd api && docker build -t fastapi_test --target test . || exit 1

echo "\nü§ñ Tests Model..."
cd ../model && docker build -t model_test --target test . || exit 1

echo "\nüé® Tests UI..."
cd ../ui && docker build -t ui_test --target test . || exit 1

echo "\n‚úÖ Tests Integraci√≥n..."
cd .. && python tests/test_integration.py || exit 1

echo "\n‚ú® ¬°Todos los tests pasaron!"
```

---

## Troubleshooting

### Problema: TLS handshake timeout con Docker Hub
```bash
ERROR: failed to do request: Head "https://registry-1.docker.io/...": net/http: TLS handshake timeout
```
**Causa:** Problema de red temporal o timeout al conectarse a Docker Hub.

**Soluci√≥n 1: Reintentar m√°s tarde**
```bash
# Esperar unos minutos y reintentar
docker build -t model_test --target test .
```

**Soluci√≥n 2: Usar contenedor corriendo (Recomendado)**
```bash
# Si ya construiste la imagen con docker-compose build
docker exec ml_service pytest -v /src/tests
```

**Soluci√≥n 3: Aumentar timeout de Docker**
```bash
# Editar Docker Desktop ‚Üí Preferences ‚Üí Docker Engine
# Agregar en el JSON:
{
  "max-download-attempts": 5,
  "max-concurrent-downloads": 1
}
# Luego restart Docker Desktop
```

**Soluci√≥n 4: Usar proxy/VPN si el problema persiste**

### Problema: Contenedor no existe (Docker Compose v2)
```bash
Error: No such container: redis
Error: No such container: model
```
**Causa:** Docker Compose v2 genera nombres como `<directorio>-<servicio>-<n√∫mero>`

**Soluci√≥n:**
```bash
# Encontrar el nombre real
docker ps --filter "name=redis" --format "{{.Names}}"

# Usar el nombre completo
docker exec assignment-redis-1 redis-cli ping

# O encontrar din√°micamente
docker ps --filter "name=redis" --format "{{.Names}}" | xargs -I {} docker exec {} redis-cli ping
```

### Problema: Error TTY "the input device is not a TTY"
```bash
Error: the input device is not a TTY
```
**Causa:** Algunos entornos no soportan modo interactivo (-it).

**Soluci√≥n:**
```bash
# Quitar flags -it
docker exec assignment-redis-1 redis-cli ping
# En lugar de:
docker exec -it assignment-redis-1 redis-cli ping
```

### Problema: Red Docker no existe
```bash
Error: network shared_network not found
```
**Soluci√≥n:**
```bash
docker network create shared_network
```

### Problema: Puerto ya en uso
```bash
Error: Bind for 0.0.0.0:8000 failed: port is already allocated
```
**Soluci√≥n:**
```bash
# Encontrar proceso usando el puerto
lsof -i :8000

# Matar proceso o cambiar puerto en docker-compose.yml
```

### Problema: TensorFlow 2.8.0 no compatible con Apple Silicon
```bash
ERROR: Could not find a version that satisfies the requirement tensorflow==2.8.0
```
**Causa:** TensorFlow 2.8.0 no tiene binarios para arquitectura ARM64 (M1/M2/M3)

**Soluci√≥n:**
```bash
# Ya corregido en model/requirements.txt
# Actualizado a tensorflow==2.13.0 que soporta Apple Silicon
# Si ves este error, hacer git pull para obtener la versi√≥n actualizada
git pull origin main
docker-compose build model --no-cache
```
Ver `docs/COMPATIBILITY_NOTES.md` para m√°s detalles.

### Problema: Pillow 11.0.0 no compatible con Python 3.8
```bash
ERROR: Could not find a version that satisfies the requirement Pillow==11.0.0
```
**Causa:** Pillow 11.0+ requiere Python 3.9+, proyecto usa Python 3.8.13

**Soluci√≥n:**
```bash
# Ya corregido en model/requirements.txt y ui/requirements.txt
# Actualizado a Pillow==10.4.0 (√∫ltima versi√≥n compatible con Python 3.8)
git pull origin main
docker-compose build --no-cache
```

### Problema: Modelo no descarga
```bash
Error downloading ResNet50 weights
```
**Soluci√≥n:**
```bash
# Verificar conexi√≥n internet
# Reintentar build
docker-compose build model --no-cache

# Si persiste, verificar que TensorFlow instal√≥ correctamente
docker run --rm ml_service python -c "import tensorflow as tf; print(tf.__version__)"
```

### Problema: Redis connection refused
```bash
redis.exceptions.ConnectionError: Connection refused
```
**Soluci√≥n:**
```bash
# Verificar Redis corriendo
docker-compose ps redis

# Verificar configuraci√≥n de red
docker-compose config | grep networks
```

### Problema: Tests fallan con import errors
```bash
ModuleNotFoundError: No module named 'fastapi'
```
**Soluci√≥n:**
```bash
# Asegurar que tests corren en Docker
cd api && docker build -t fastapi_test --target test .

# NO ejecutar pytest directamente fuera de Docker
```

### Problema: UI no carga
```bash
This site can't be reached
```
**Soluci√≥n:**
```bash
# Verificar contenedor corriendo
docker-compose ps ui

# Ver logs
docker-compose logs ui

# Verificar puerto correcto
curl http://localhost:9090
```

### Problema: Predicciones muy lentas
```bash
Request timeout despu√©s de 60 segundos
```
**Soluci√≥n:**
```bash
# Ver logs del modelo
docker-compose logs model

# Verificar CPU/Memory
docker stats

# En Apple Silicon, TensorFlow 2.13 es optimizado pero puede ser lento
# la primera predicci√≥n (carga del modelo)

# Considerar:
# 1. Aumentar timeout en api/app/model/services.py
# 2. Implementar √âPICA 7 (batch processing) para mejor throughput
# 3. Escalar servicio: docker-compose up --scale model=2
```

### Problema: Warning sobre version en docker-compose
```bash
WARN: the attribute `version` is obsolete
```
**Causa:** Docker Compose v2 deprec√≥ el campo `version:`

**Soluci√≥n:**
```bash
# Este es solo un warning, NO afecta funcionalidad
# Puede ignorarse de forma segura
# Si deseas eliminarlo, quitar l√≠nea 1 de docker-compose.yml:
# version: "3.2"  <- Eliminar esta l√≠nea
```

### Problema: Puertos en formato diferente al esperado
```bash
# Ves: published: "8000" / target: 5000
# En lugar de: 8000:5000
```
**Causa:** Docker Compose v2 usa formato YAML expandido

**Soluci√≥n:**
```bash
# Esto es correcto y equivalente:
# published: "8000" + target: 5000 = 8000:5000
# No requiere correcci√≥n
# Ver docs/COMPATIBILITY_NOTES.md secci√≥n "Verificaci√≥n de Puertos"
```

---

## Checklist Final

Antes de considerar el proyecto completo:

### Funcionalidad
- [ ] Sistema se levanta con `docker-compose up -d` sin errores
- [ ] Login funciona en UI y API
- [ ] Clasificaci√≥n de im√°genes retorna resultados correctos
- [ ] Feedback se guarda en base de datos
- [ ] Tests unitarios pasan (api, model, ui)
- [ ] Tests de integraci√≥n pasan (2/2)
- [ ] Stress testing ejecutado sin crashes

### Performance
- [ ] API responde en < 3 segundos
- [ ] Predicciones completan en < 5 segundos
- [ ] Sistema maneja 10+ usuarios concurrentes
- [ ] No hay memory leaks en tests largos

### C√≥digo
- [ ] No hay TODOs pendientes
- [ ] C√≥digo formateado con Black e isort
- [ ] Docstrings presentes
- [ ] No hay credenciales hardcodeadas
- [ ] Logs informativos implementados

### Documentaci√≥n
- [ ] README actualizado
- [ ] Reporte de stress testing completo
- [ ] Screenshots incluidos
- [ ] Instrucciones claras de setup
- [ ] Troubleshooting documentado

### Git
- [ ] .gitignore protege archivos sensibles
- [ ] Commits siguen formato [EPIC-X-TX]
- [ ] Branches organizados por √©pica
- [ ] Historia de commits clara

### Opcional (Batch Processing)
- [ ] Batch processing implementado
- [ ] Comparativa de performance documentada
- [ ] Reporte incluye secci√≥n de batch

---

**√öltima actualizaci√≥n:** 2026-01-13  
**Versi√≥n:** 1.0
